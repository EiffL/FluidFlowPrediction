{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from fluidflow.nets import  dense_encoder, dense_decoder\n",
    "from fluidflow.bijections import Orthogonal\n",
    "from fluidflow.optimizers import RMSpropNatGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n",
    "x2 = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n",
    "\n",
    "bijection = Orthogonal(hidden_size, hidden_size)\n",
    "eigv = tf.get_variable(name='eigen_values',\n",
    "                       initializer=tf.ones(hidden_size, dtype=tf.float32))\n",
    "\n",
    "# Encode the data to  lower dimensionality space\n",
    "z1 = dense_encoder(x, latent_size=hidden_size)\n",
    "\n",
    "# Apply the orthogonal transform\n",
    "h = bijection.forward(z1)\n",
    "# Apply a vector of eigen values\n",
    "h= h * eigv\n",
    "# Apply the transpose of the orhogonal transform\n",
    "z2 = bijection.inverse(h)\n",
    "\n",
    "xrec = dense_decoder(z1)\n",
    "\n",
    "# Predicting next time step from residual unit\n",
    "xpred = dense_decoder(z1 + z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.l2_loss(xrec - x) + tf.nn.l2_loss(xpred - x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appling an orthogonality preserving step to Orthogonal//orthogonal_stiefel/A:0\n",
      "Appling standard rmsprop to eigen_values:0\n",
      "Appling standard rmsprop to encoder/dense/kernel:0\n",
      "Appling standard rmsprop to encoder/dense/bias:0\n",
      "Appling standard rmsprop to encoder/dense_1/kernel:0\n",
      "Appling standard rmsprop to encoder/dense_1/bias:0\n",
      "Appling standard rmsprop to encoder/dense_2/kernel:0\n",
      "Appling standard rmsprop to encoder/dense_2/bias:0\n",
      "Appling standard rmsprop to decoder/dense/kernel:0\n",
      "Appling standard rmsprop to decoder/dense/bias:0\n",
      "Appling standard rmsprop to decoder/dense_1/kernel:0\n",
      "Appling standard rmsprop to decoder/dense_1/bias:0\n",
      "Appling standard rmsprop to decoder/dense_2/kernel:0\n",
      "Appling standard rmsprop to decoder/dense_2/bias:0\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "optimizer = RMSpropNatGrad(learning_rate=0.001,\n",
    "                           global_step=global_step)\n",
    "\n",
    "opt_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just got to do some training now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - GPU",
   "language": "python",
   "name": "gpu-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
